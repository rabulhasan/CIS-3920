{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0cda99",
   "metadata": {},
   "source": [
    "### Rabiul Hasan\n",
    "#### CIS3920\n",
    "##### In class assignments 01\n",
    "##### 03/13/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6fd86d",
   "metadata": {},
   "source": [
    "#### Kumar Ch2:\n",
    "Question: 12\n",
    "Distinguish between noise and outliers. Be sure to consider the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d9a2a",
   "metadata": {},
   "source": [
    "#####  a) Is noise ever interesting or desirable? Outliers?\n",
    "-\tNoise is the random component of a measurement error. It typically involves the distortion of a value or the addition of spurious objects. Outliers can be legitimate objects of data or values, i.e., identifying outliers can be the main objective of some data mining tasks. However, outliers can be interesting or desirable, such as, detecting fraud etc. but noise is an error, so we want to eliminate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4db663",
   "metadata": {},
   "source": [
    "##### b)\tCan noise objects be outliers? \n",
    "- \tYes, noise objects can be appeared as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88699c0",
   "metadata": {},
   "source": [
    "##### c)\tAre noise objects always outliers? \n",
    "-\tNoise objects can appear as normal data. So, noise objects are not always outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b2fb0",
   "metadata": {},
   "source": [
    "##### d)\tAre outliers always noise objects? \n",
    "-\tOutliers might be a legitimate data but looks like it doesnâ€™t belong in the data set. But noise is an error and can be sit with normal data range. So, outliers arenâ€™t always noise objects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec85dc6",
   "metadata": {},
   "source": [
    "##### e)\tCan noise make a typical value into an unusual one, or vice versa? \n",
    "-\tThe source of noise in data can randomly make some values appear as unusual, or some outliers as typical data objects. So, itâ€™s very much possible that it makes a typical value into an unusual one or vice versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045b54f",
   "metadata": {},
   "source": [
    "#### Question: 24\n",
    "##### Proximity is typically defined between a pair of objects.Define two ways in which you might define the proximity among a group of objects.\n",
    "Two ways to define proximity among a group are the following:\n",
    "\t- based on pairwise proximity\n",
    "\t- for points in Euclidean space compute a centroid and then compute the sum or average of the distances of the points to the centroid. \n",
    " \n",
    "#### How might you define the distance between two sets of points in Euclidean space? \n",
    "We calculate distance between two sets of points in Euclidean space with following formula:\n",
    " d = âˆš((x_(2-) x_1 )^2+ã€–(y_2-y_1)ã€—^2 ) it is basically, centroids of the two sets of points. The centroid is simply the vector sum of all the Euclidean vectors scaled by their number.\n",
    "\n",
    "#### How might you define the proximity between two sets of data objects? (Make no assumption about the data objects, except that a proximity  measure is defined between any pair of objects.) \n",
    "One approaches to define the proximity between two sets of data objects are to take the least amount or most amount proximity of all such pairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893a539",
   "metadata": {},
   "source": [
    "Trevor Ch3:\n",
    "#### Q2: Carefully explain the differences between the kNN classifier and kNN regression methods. \n",
    "\n",
    "|| The KNN classifier|\tThe KNN regression method|\n",
    "|---|---|---|\n",
    "| **Usefulness**|used to solve classification problems|\tused to solve regression problems|\n",
    "|**Calculation process**|by identifying the neighborhood of x_0 and then estimating the conditional probability *ð’« (ð’´ = ð’¿ \\|ð’³ = x_0)* for class ð’¿ as the fraction of points in the neighborhood whose response values equal ð’¿|\tby again identifying the neighborhood of x_0 and then estimating *f(x_0)* as the average of all the training responses in the neighborhood.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2263219",
   "metadata": {},
   "source": [
    "# Trevor Ch5:\n",
    "Question:  5 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066dfbf5",
   "metadata": {},
   "source": [
    "### Fit a logistic regression model that uses income and balance to predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477d8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.csv(\"Default.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59841a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = \"binomial\", \n",
       "    data = df)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4725  -0.1444  -0.0574  -0.0211   3.7245  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***\n",
       "income       2.081e-05  4.985e-06   4.174 2.99e-05 ***\n",
       "balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1579.0  on 9997  degrees of freedom\n",
       "AIC: 1585\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(7)\n",
    "fit.glm = glm(default ~ income + balance, data = df, family = \"binomial\")\n",
    "summary(fit.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9dee67",
   "metadata": {},
   "source": [
    "### Split the sample set into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df49fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sample(dim(df)[1], (dim(df)[1])*.5)\n",
    "test = df[-train,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b891cb4",
   "metadata": {},
   "source": [
    "### Fit a multiple logistic regression model using only the training observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152c90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.glm = glm(default ~ income + balance, data = test, family = \"binomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8965cf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = \"binomial\", \n",
       "    data = test)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.1919  -0.1349  -0.0531  -0.0188   3.7829  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.194e+01  6.478e-01 -18.432  < 2e-16 ***\n",
       "income       2.388e-05  7.335e-06   3.256  0.00113 ** \n",
       "balance      5.766e-03  3.372e-04  17.102  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1382.01  on 4999  degrees of freedom\n",
       "Residual deviance:  736.93  on 4997  degrees of freedom\n",
       "AIC: 742.93\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(fit.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a0772f",
   "metadata": {},
   "source": [
    "### Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4adc3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0234"
      ],
      "text/latex": [
       "0.0234"
      ],
      "text/markdown": [
       "0.0234"
      ],
      "text/plain": [
       "[1] 0.0234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.probs = predict(fit.glm, newdata = test, type=\"response\")\n",
    "glm.pred=rep(\"No\",5000)\n",
    "glm.pred[glm.probs>0.5] = \"Yes\"\n",
    "mean(glm.pred != test$default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee12a7",
   "metadata": {},
   "source": [
    "### Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8c0a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.0266\n",
      "[1] 0.0276\n",
      "[1] 0.027\n"
     ]
    }
   ],
   "source": [
    "for(i in 1:3) {\n",
    "    train = sample(dim(df)[1], (dim(df)[1])*.5)\n",
    "    test = df[-train,]\n",
    "    fit.glm = glm(default ~ income + balance, data = test, family = \"binomial\")\n",
    "    glm.probs = predict(fit.glm, newdata = test, type=\"response\")\n",
    "    glm.pred=rep(\"No\",length(glm.probs))\n",
    "    glm.pred[glm.probs>0.5] = \"Yes\"\n",
    "    print(mean(glm.pred != test$default))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0258c",
   "metadata": {},
   "source": [
    "### Now consider a logistic regression model that predicts the prob ability of default using income , balance , and a dummy variable for student . Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3662f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.0262\n",
      "[1] 0.0292\n",
      "[1] 0.0258\n"
     ]
    }
   ],
   "source": [
    "# include a dummy variable and run the code for 3 times in a for loop\n",
    "for(i in 1:3) {\n",
    "    train = sample(dim(df)[1], (dim(df)[1])*.5)\n",
    "    test = df[-train,]\n",
    "    fit.glm = glm(default ~ income + balance + student, data = test, family = \"binomial\")\n",
    "    glm.probs = predict(fit.glm, newdata = test, type=\"response\")\n",
    "    glm.pred=rep(\"No\",length(glm.probs))\n",
    "    glm.pred[glm.probs>0.5] = \"Yes\"\n",
    "    print(mean(glm.pred != test$default))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3024b8f",
   "metadata": {},
   "source": [
    "### Conclution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23522f6e",
   "metadata": {},
   "source": [
    "After including a dummy variable for student does not change the test error rate. Before the including value was 2.6%-2.7%, after including the dummy variable the test error rate is 2.6%-2.8% which is very little change, so we can elimenate or ignore it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdcb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
